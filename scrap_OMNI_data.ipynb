{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da8d9a6-4b0a-47e1-9a2b-c680f25bb049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ajivani/time_series_transformers'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rich.progress import track\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72a39baf-089a-4684-aab5-e5952d2ebf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd0f6625ea84da09e98681426cd9291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "base_url = \"https://spdf.gsfc.nasa.gov/pub/data/omni/high_res_omni/modified/monthly_1min/\"\n",
    "\n",
    "save_dir = \"./solar_wind_data/omni/high_res_1min/\"\n",
    "\n",
    "# Check and create directory if not exists\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for year in track(range(2014, 2018), description=\"Processing Year by Year...\"):\n",
    "# for year in track(range(1995, 2023), description=\"Processing Year by Year...\"):\n",
    "    for month in range(1, 13):\n",
    "        # Construct the filename and its URL\n",
    "        filename = f\"omni_min{year}{str(month).zfill(2)}.asc\"\n",
    "        file_url = urljoin(base_url, filename)\n",
    "\n",
    "        # Attempt to download the file\n",
    "        response = requests.get(file_url, stream=True)\n",
    "\n",
    "        # If the download is successful, save the file\n",
    "        if response.status_code == 200:\n",
    "            with open(os.path.join(save_dir, filename), 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "        else:\n",
    "            print(f\"Failed to download {filename}.\")\n",
    "\n",
    "print(\"Download complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8126311f-bb76-4621-b800-0a5b84b60a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load IGRF coefficients ...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import geopack\n",
    "import datetime\n",
    "import geopack.geopack as gp\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8dd5c9b-b85c-40ff-9501-d6c4cebb19e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae2af080c784df5b0524fb5a079772d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading complete.\n"
     ]
    }
   ],
   "source": [
    "# Define the time range\n",
    "start_year, start_month = 2014, 1\n",
    "end_year, end_month = 2017, 12\n",
    "\n",
    "# Prepare an empty DataFrame to hold the data\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Loop through each year and month\n",
    "for year in track(range(start_year, end_year+1)):\n",
    "    for month in range(1, 13):\n",
    "        if year == start_year and month < start_month:\n",
    "            continue\n",
    "        if year == end_year and month > end_month:\n",
    "            break\n",
    "        # Construct the filename\n",
    "        filename = f\"omni_min{year}{str(month).zfill(2)}.asc\"\n",
    "        file_path = os.path.join(save_dir, filename)\n",
    "\n",
    "        # Check if the file exists\n",
    "        if os.path.isfile(file_path):\n",
    "            # Read the file into a DataFrame\n",
    "            df_temp = np.loadtxt(file_path)  # Add delimiter or other arguments if needed\n",
    "            df = pd.concat([df, pd.DataFrame(df_temp)], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"{filename} not found.\")\n",
    "\n",
    "# Function to convert year, day of year, hour, and minute into a datetime object\n",
    "def convert_to_datetime(row):\n",
    "    return datetime.datetime(int(row[0]), 1, 1, int(row[2]), int(row[3])) + pd.Timedelta(days=int(row[1])-1)\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "df['Datetime'] = df.apply(convert_to_datetime, axis=1)\n",
    "\n",
    "# Set the new datetime column as the index\n",
    "df.set_index('Datetime', inplace=True)\n",
    "# Rename columns\n",
    "df.drop(columns=df.columns[:4], axis=1, inplace=True)\n",
    "df.columns = ['ID for IMF spacecraft', 'ID for SW Plasma spacecraft', '# of points in IMF averages', \n",
    "              '# of points in Plasma averages', 'Percent interp', 'Timeshift, sec', 'RMS, Timeshift', \n",
    "              'RMS, Phase front normal', 'Time btwn observations, sec', 'Field magnitude average', \n",
    "              'Bx, nT (GSE, GSM)', 'By, nT (GSE)', 'Bz, nT (GSE)', 'By, nT (GSM)', 'Bz, nT (GSM)', 'RMS SD B scalar',\n",
    "              'RMS SD field vector', 'Flow speed, km/s', 'Vx Velocity, km/s, GSE', 'Vy Velocity, km/s, GSE', \n",
    "              'Vz Velocity, km/s, GSE', 'Proton Density, n/cc', 'Temperature, K', 'Flow pressure, nPa', \n",
    "              'Electric field, mV/m', 'Plasma beta', 'Alfven mach number', 'X(s/c), GSE, Re', 'Y(s/c), GSE, Re', \n",
    "              'Z(s/c), GSE, Re', 'BSN location, Xgse, Re', 'BSN location, Ygse, Re', 'BSN location, Zgse, Re',\n",
    "              'AE-index, nT', 'AL-index, nT', 'AU-index, nT', 'SYM/D index, nT', 'SYM/H index, nT', \n",
    "              'ASY/D index, nT', 'ASY/H index, nT', 'Na/Np Ratio', 'Magnetosonic mach number']\n",
    "df.to_pickle(\"./solar_wind_data/processed_data/OMNI_raw.pkl\")\n",
    "print(\"Data loading complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22aff457-fe80-4260-9dec-af2515c9711d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2139087/3387998188.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final.loc[:, 'B'] = np.sqrt(df_final['Bx, nT (GSE, GSM)']**2 + df_final['By, nT (GSM)']**2 + df_final['Bz, nT (GSM)']**2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"./solar_wind_data/processed_data/OMNI_raw.pkl\")\n",
    "df = df[['Bx, nT (GSE, GSM)', 'By, nT (GSM)', 'Bz, nT (GSM)', 'Vx Velocity, km/s, GSE',\n",
    "         'Proton Density, n/cc', 'Temperature, K', 'Flow speed, km/s', 'Alfven mach number', 'Magnetosonic mach number']]\n",
    "\n",
    "df = df.replace(99.9, np.nan)\n",
    "df = df.replace(999.99, np.nan)\n",
    "df = df.replace(9999.99, np.nan)\n",
    "df = df.replace(99999.9, np.nan)\n",
    "df = df.replace(9999999., np.nan)\n",
    "for col in df.columns:\n",
    "    mask = df[col].notna()\n",
    "    a = mask.ne(mask.shift()).cumsum()\n",
    "    df = df[(a.groupby(a).transform('size') < 15) | mask]\n",
    "df = df.ffill()\n",
    "\n",
    "df_final = df.dropna()\n",
    "\n",
    "df_final.loc[:, 'B'] = np.sqrt(df_final['Bx, nT (GSE, GSM)']**2 + df_final['By, nT (GSM)']**2 + df_final['Bz, nT (GSM)']**2)\n",
    "\n",
    "df_final.to_pickle(\"./solar_wind_data/processed_data/OMNI_final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca6169a-57d5-4eb1-b283-fb9cc7ae1a15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
